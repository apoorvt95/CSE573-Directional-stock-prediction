{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: transformers in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (2.8.0)\nRequirement already satisfied: sacremoses in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.41)\nRequirement already satisfied: tokenizers==0.5.2 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (0.5.2)\nRequirement already satisfied: numpy in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\nRequirement already satisfied: boto3 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (1.11.15)\nRequirement already satisfied: tqdm>=4.27 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (4.45.0)\nRequirement already satisfied: requests in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\nRequirement already satisfied: sentencepiece in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (0.1.85)\nRequirement already satisfied: regex!=2019.12.17 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (2020.4.4)\nRequirement already satisfied: filelock in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: click in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\nRequirement already satisfied: six in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.12.0)\nRequirement already satisfied: joblib in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.3.3)\nRequirement already satisfied: botocore<1.15.0,>=1.14.15 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (1.14.15)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\nRequirement already satisfied: docutils<0.16,>=0.10 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/akshaykumar/anaconda3/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.8.0)\n"
    }
   ],
   "source": [
    "!pip install transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10000\n10000\n"
    }
   ],
   "source": [
    "df=pd.read_csv('./AmazonDataset/Label10000.csv')\n",
    "print(len(df))\n",
    "# df = df[df['text'].str.split().str.len().gt(5)]\n",
    "# df = df[df['text'].str.split().str.len().lt(30)]\n",
    "df=df.reset_index(drop=None)\n",
    "print(len(df))\n",
    "# news=df['text']\n",
    "# label=df['label']\n",
    "# len(news)\n",
    "# current_words=[]\n",
    "# for i in range(len(news)):\n",
    "#   # for word in news.loc[i].split(\" \"):\n",
    "#     current_words.append(news.loc[i])\n",
    "# print((current_words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "appl      5971\naapl      2096\ninc       2077\nshare     1790\nnasdaq    1219\nbuy        978\niphon      973\nrate       963\nreport     949\nprice      917\ndtype: int64\nNot Common words\nappl           5971\naapl           2096\ninc            2077\nshare          1790\nnasdaq         1219\n               ... \nyearsellsid       1\nlarson            1\nreportlet         1\ncommonli          1\naroundappl        1\nLength: 13214, dtype: int64\n"
    }
   ],
   "source": [
    "df['word_count']=df['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "df.word_count.describe()\n",
    "common_words=pd.Series(''.join(df['text']).split()).value_counts()\n",
    "print(common_words[:10])\n",
    "print(\"Not Common words\")\n",
    "print(common_words[-30000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------> 0\n"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "most_common=common_words[:3]\n",
    "least_common=common_words[-12000:]\n",
    "texts=[]\n",
    "labels=[]\n",
    "def removeWords(words):\n",
    "    final_words=[]\n",
    "    for word in words:\n",
    "        if not (word in most_common or word in least_common):\n",
    "            final_words.append(word)\n",
    "    return final_words\n",
    "for i in range(len(df)):\n",
    "    if i%10000==0:\n",
    "        print(\"------>\",i)\n",
    "    words=word_tokenize(df.loc[i].text)\n",
    "    # print(df.loc[i].text)\n",
    "    words=removeWords(words)\n",
    "    extracted_sentence=' '.join(word for word in words)\n",
    "    # print(df.loc[i].text)\n",
    "    texts.append(extracted_sentence)\n",
    "    labels.append(df.loc[i]['label'])\n",
    "new_df=pd.DataFrame({\n",
    "    'text':texts,\n",
    "    'label':labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                   text  label\n9995              immedi respond request comment friday      1\n9996                            great news iphon se fan      1\n9997     earli nasdaq introduc smartphon known iphon se      1\n9998  nearli two year launch iphon se still nt updat...      1\n9999  main compani tri boost sale iphon se price eve...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9995</th>\n      <td>immedi respond request comment friday</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>great news iphon se fan</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>earli nasdaq introduc smartphon known iphon se</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>nearli two year launch iphon se still nt updat...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>main compani tri boost sale iphon se price eve...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=new_df['text']\n",
    "label=new_df['label']\n",
    "tokenized = news.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       also featur annual tom speaker new job profess...\n1       huge anticip iphon x samsung follow note big y...\n2            iphon x best phone money issu one expens buy\n3       premium devic start per month depend purchas p...\n4       face id technolog camera help make iphon need ...\n                              ...                        \n9995                immedi respond request comment friday\n9996                              great news iphon se fan\n9997       earli nasdaq introduc smartphon known iphon se\n9998    nearli two year launch iphon se still nt updat...\n9999    main compani tri boost sale iphon se price eve...\nName: text, Length: 10000, dtype: object"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    [101, 2036, 8658, 3126, 3296, 3419, 5882, 2047...\n1    [101, 4121, 3424, 6895, 2361, 12997, 8747, 106...\n2    [101, 12997, 8747, 1060, 2190, 3042, 2769, 263...\n3    [101, 12882, 14386, 2278, 2707, 2566, 3204, 12...\n4    [101, 2227, 8909, 21416, 21197, 4950, 2393, 21...\nName: text, dtype: object"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[  101,  2036,  8658, ...,     0,     0,     0],\n       [  101,  4121,  3424, ...,     0,     0,     0],\n       [  101, 12997,  8747, ...,     0,     0,     0],\n       ...,\n       [  101,  4656,  2072, ...,     0,     0,     0],\n       [  101,  2379,  3669, ...,     0,     0,     0],\n       [  101,  2364,  4012, ...,     0,     0,     0]])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10000, 238)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10000, 238)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}