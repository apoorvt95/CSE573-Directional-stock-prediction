{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "XYXTmbqOB4w1",
    "outputId": "5e314735-336c-464b-bee6-8c2c26ce229e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading collection 'popular'\n[nltk_data]    | \n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package names to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package omw to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package punkt to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /Users/akshaykumar/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection popular\n"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "Mra9shjGR_mJ",
    "outputId": "f4659c44-bc87-428d-e709-3cbc117470d6"
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('ExtractedNewsSentenceWise2.csv',encoding='latin1')\n",
    "dataset=dataset[['text','day','24_time']]\n",
    "dataset=dataset.dropna()\n",
    "dataset=dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text         day   24_time\n0  nape summit week will also feature the annual ...  2017-12-07  22:00:00\n1  from appleÃ¢ÂÂs hugely anticipated iphone x ...  2017-12-08  23:37:00\n2  iphone x Ã¢ÂÂ best phone if money isnÃ¢ÂÂt...  2017-12-08  23:37:00\n3  more appleÃ¢ÂÂs (aapl) most premium of premi...  2017-12-08  23:37:00\n4  the xÃ¢ÂÂs spot-on face id facial-recognitio...  2017-12-08  23:37:00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>day</th>\n      <th>24_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nape summit week will also feature the annual ...</td>\n      <td>2017-12-07</td>\n      <td>22:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>from appleÃ¢ÂÂs hugely anticipated iphone x ...</td>\n      <td>2017-12-08</td>\n      <td>23:37:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iphone x Ã¢ÂÂ best phone if money isnÃ¢ÂÂt...</td>\n      <td>2017-12-08</td>\n      <td>23:37:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>more appleÃ¢ÂÂs (aapl) most premium of premi...</td>\n      <td>2017-12-08</td>\n      <td>23:37:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the xÃ¢ÂÂs spot-on face id facial-recognitio...</td>\n      <td>2017-12-08</td>\n      <td>23:37:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "6RsSlVkiRy5u",
    "outputId": "31dd1dd7-b03c-4426-c2d0-2ba728ade380"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "548136\n521591\n419416\n"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "# dataset=dataset[dataset['text'].str.isalnum()]\n",
    "dataset=dataset[dataset['text'].str.match('^[A-Z a-z 0-9]+')]\n",
    "dataset=dataset[dataset['day'].str.match('^[0-9]+[-]')]\n",
    "print(len(dataset))\n",
    "dataset=dataset.drop_duplicates(keep=False)\n",
    "dataset=dataset.reset_index(drop=True)\n",
    "dataset.head()\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "jdDiUyGIeyOY",
    "outputId": "3436bb58-0830-423a-c932-016ed47f4ce8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "text         day   24_time\n0  nape summit week will also feature the annual ...  2017-12-07  22:00:00\n1  from appleÃ¢ÂÂs hugely anticipated iphone x ...  2017-12-08  23:37:00\n2  iphone x Ã¢ÂÂ best phone if money isnÃ¢ÂÂt...  2017-12-08  23:37:00\n3  more appleÃ¢ÂÂs (aapl) most premium of premi...  2017-12-08  23:37:00\n4  the xÃ¢ÂÂs spot-on face id facial-recognitio...  2017-12-08  23:37:00\n"
    }
   ],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yW9v6QkgDpdE"
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import LancasterStemmer,PorterStemmer\n",
    "def nonAsciiChar(words):\n",
    "    final_words=[]\n",
    "    for word in words:\n",
    "        word=word.lower()\n",
    "        word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        word=re.sub(\"\\d+\", \"\",word)\n",
    "        word=re.sub('[^a-zA-Z]+','',word)\n",
    "        f_word=unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        final_words.append(f_word)\n",
    "        \n",
    "    return final_words\n",
    "\n",
    "def stopWords(words):\n",
    "    final_words=[]\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            final_words.append(word)\n",
    "    return final_words\n",
    "\n",
    "def removeSpace(words):\n",
    "    final_words=[]\n",
    "    for word in words:\n",
    "        if word!='':\n",
    "            final_words.append(word)\n",
    "    return final_words\n",
    "          \n",
    "def stem_words(words):\n",
    "    stemmer = PorterStemmer()\n",
    "    final_stem=[]\n",
    "    for word in words:\n",
    "        word=stemmer.stem(word)\n",
    "        if word not in final_stem:\n",
    "            final_stem.append(word)\n",
    "    return final_stem\n",
    "\n",
    "def remove_links(words):\n",
    "    final_words=[]\n",
    "    for word in words:\n",
    "        if not re.match('[www]',word):\n",
    "            final_words.append(word)\n",
    "    return final_words\n",
    "\n",
    "def all_data_extraction(words):\n",
    "    words=nonAsciiChar(words)\n",
    "    words=stopWords(words)\n",
    "    words=removeSpace(words)\n",
    "    words=stem_words(words)\n",
    "    # print((words))\n",
    "    words=remove_links(words)\n",
    "    # print((words))\n",
    "    return words\n",
    "# words = word_tokenize(dataset.loc[349].text)\n",
    "\n",
    "# words=all_data_extraction(words)\n",
    "# print(words)\n",
    "# print(' '.join(word for word in words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdaCmwoLDxo_"
   },
   "outputs": [],
   "source": [
    "# dataset=dataset[['text','day','24_time']]\n",
    "# dataset=dataset.dropna()\n",
    "# dataset=dataset.reset_index(drop=True)\n",
    "# dataset.head()\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "0N7KKAXqD17g",
    "outputId": "5df91909-db45-42f6-f403-5bce5ace66f6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "I------>  0\nI------>  10000\nI------>  20000\nI------>  30000\nI------>  40000\nI------>  50000\nI------>  60000\nI------>  70000\nI------>  80000\nI------>  90000\nI------>  100000\nI------>  110000\nI------>  120000\nI------>  130000\nI------>  140000\nI------>  150000\nI------>  160000\nI------>  170000\nI------>  180000\nI------>  190000\nI------>  200000\nI------>  210000\nI------>  220000\nI------>  230000\nI------>  240000\nI------>  250000\nI------>  260000\nI------>  270000\nI------>  280000\nI------>  290000\nI------>  300000\nI------>  310000\nI------>  320000\nI------>  330000\nI------>  340000\nI------>  350000\nI------>  360000\nI------>  370000\nI------>  380000\nI------>  390000\nI------>  400000\nI------>  410000\n"
    }
   ],
   "source": [
    "texts=[]\n",
    "days=[]\n",
    "time=[]\n",
    "data_text=[]\n",
    "for i in range(len(dataset)):\n",
    "    if i%10000==0:\n",
    "      print(\"I------> \",i)\n",
    "    words=word_tokenize(dataset.loc[i].text)\n",
    "    words=all_data_extraction(words)\n",
    "    extracted_sentence=' '.join(word for word in words)\n",
    "    texts.append(extracted_sentence)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    days.append(dataset.loc[i]['day'])\n",
    "    time.append(dataset.loc[i]['24_time'])\n",
    "df=pd.DataFrame({\n",
    "    'text':texts,\n",
    "    'day':days,\n",
    "    'time':time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8Hbx4kvUQ_m0",
    "outputId": "afd143f1-2d3d-4132-fee1-872fcd5d4242"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "419416\n"
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LPX31h4PZ2j"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"FinalExtractedSentenceWise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "E8gRNAQiPkxd",
    "outputId": "85b44a42-3349-4a5f-e78c-2461d74d7ee3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "419416\n419414\n"
    }
   ],
   "source": [
    "df=pd.read_csv('./FinalExtractedSentenceWise.csv')\n",
    "print(len(df))\n",
    "df=df.reset_index(drop=True)\n",
    "df=df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v2suIOzYRFly",
    "outputId": "06436d20-3ba6-4d5b-ac16-b54acc0cf9f0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "419414\n"
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1udD4uUNRKfS",
    "outputId": "56a5ef5a-0d68-4b64-f760-211fea30ee1c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22:00:00\nTrue\n"
    }
   ],
   "source": [
    "print((df.loc[0]['time']))\n",
    "if \"4:32:00\"< \"63:30\":\n",
    "  print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ulEdAhgxecSl",
    "outputId": "ad0d9e4b-8e2f-4416-9a3b-e786560b7c5a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          day   time    price\n0           .  19:30  106.029\n1  2016.03.16  20:30  105.099\n2  2016.03.17  12:30  105.269\n3  2016.03.17  13:30  105.479\n4  2016.03.17  14:30  105.609",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day</th>\n      <th>time</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.</td>\n      <td>19:30</td>\n      <td>106.029</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016.03.16</td>\n      <td>20:30</td>\n      <td>105.099</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016.03.17</td>\n      <td>12:30</td>\n      <td>105.269</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016.03.17</td>\n      <td>13:30</td>\n      <td>105.479</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016.03.17</td>\n      <td>14:30</td>\n      <td>105.609</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.strptime(df.loc[0].day,'%Y-%m-%d').strftime('%Y.%m.%d')\n",
    "amz_df=pd.read_csv('./CHARTS/APPLE60.csv',names=['day','time','price','x1','x2','x3','x4'])\n",
    "amz_df=amz_df[['day','time','price']]\n",
    "amz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAIYZ9gNGuq9"
   },
   "outputs": [],
   "source": [
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cStGGQzMMC8R"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"FinalExtractedDataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2D4uibJsHD5G"
   },
   "outputs": [],
   "source": [
    "def convert_news_time(time):\n",
    "  time=datetime.strptime(time, '%H:%M:%S')\n",
    "  return time\n",
    "\n",
    "def convert_chart_time(time):\n",
    "  time=datetime.strptime(time, '%H:%M')\n",
    "  return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uXmV5rR3g5jO",
    "outputId": "e78b8c25-074d-49f6-ea73-8b01530cb5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4174",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 4174 is not in range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b265d5276b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mconvert_news_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mconvert_chart_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"19:30\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconvert_news_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mconvert_chart_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"20:30\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mamz_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mamz_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m       \u001b[0mamazon_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3537\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4174"
     ]
    }
   ],
   "source": [
    "amazon_text=[]\n",
    "amazon_label=[]\n",
    "for i in range(len(df)):\n",
    "  date=datetime.strptime(df.loc[i].day,'%Y-%m-%d').strftime('%Y.%m.%d')\n",
    "  if i%10000==0 and i!=0:\n",
    "    label_p=pd.DataFrame({\n",
    "        'text':amazon_text,\n",
    "        'label':amazon_label\n",
    "    })\n",
    "    label_p.to_csv('Label'+str(i)+'.csv')\n",
    "    print(i)\n",
    "  amazon_text.append(df.loc[i].text)\n",
    "  for k in range(len(amz_df)):\n",
    "    if amz_df.loc[k].day==date:\n",
    "       j=k\n",
    "       break\n",
    "\n",
    "  if convert_news_time(df.loc[i].time)<convert_chart_time(\"13:30\"):\n",
    "    # print(df.loc[i].time)\n",
    "    if amz_df.loc[j-1].price<amz_df.loc[j].price:\n",
    "      amazon_label.append(1)\n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"13:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"14:30\"):\n",
    "    if amz_df.loc[j].price<amz_df.loc[j+1].price:\n",
    "      amazon_label.append(1)\n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"14:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"15:30\"):\n",
    "    if amz_df.loc[j+1].price<amz_df.loc[j+2].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"15:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"16:30\"):\n",
    "    if amz_df.loc[j+2].price<amz_df.loc[j+3].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"16:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"17:30\"):\n",
    "    if amz_df.loc[j+3].price<amz_df.loc[j+4].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "\n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"17:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"18:30\"):\n",
    "    if amz_df.loc[j+4].price<amz_df.loc[j+5].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "\n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"18:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"19:30\"):\n",
    "    if amz_df.loc[j+5].price<amz_df.loc[j+6].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "\n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"19:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"20:30\"):\n",
    "    if amz_df.loc[j+6].price<amz_df.loc[j+7].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "    \n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"20:30\") and convert_news_time(df.loc[i].time)<convert_chart_time(\"21:30\"):\n",
    "    if amz_df.loc[j+7].price<amz_df.loc[j+8].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "\n",
    "  elif convert_news_time(df.loc[i].time)>=convert_chart_time(\"21:30\"):\n",
    "    if amz_df.loc[j+8].price<amz_df.loc[j+9].price:\n",
    "      amazon_label.append(1)\n",
    "      \n",
    "    else:\n",
    "      amazon_label.append(0)\n",
    "      \n",
    "label_p=pd.DataFrame({\n",
    "        'text':amazon_text,\n",
    "        'label':amazon_label\n",
    "    })\n",
    "label_p.to_csv('Label'+str(i)+'.csv')\n",
    "\n",
    "print(amazon_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "U2zYke8qPo2D",
    "outputId": "8a04c819-2cb1-489b-cd17-366747345ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(amazon_label))\n",
    "print(len(df.loc[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ds2twoOQEJjt",
    "outputId": "cf5181e7-3232-4ddd-9a5f-e31ff5fd5a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "date_time_str=\"4:32:00\"\n",
    "date_time_str1=\"13:30\"\n",
    "time=convert_news_time(date_time_str)\n",
    "time1=convert_chart_time(date_time_str1)\n",
    "\n",
    "if time<time1:\n",
    "  print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPitiVEbMnoH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ExtractionDataSet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}